\providecommand{\bbobecdfcaptionsinglefunctionssingledim}[1]{
Empirical cumulative distribution of simulated (bootstrapped)
             runtimes, measured in number of objective function evaluations,
             divided by dimension (FEvals/DIM) for the $51$ 
             targets $10^{[-8..2]}$ in dimension #1.
}
\providecommand{\cocoversion}{\hspace{\textwidth}\scriptsize\sffamily{}\color{Gray}Data produced with COCO v2.4}
\providecommand{\numofalgs}{7}
\providecommand{\bbobECDFslegend}[1]{
Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for $51$ targets with target precision in $10^{[-8..2]}$ for all functions and subgroups in #1-D. As reference algorithm, the best algorithm from BBOB 2009 is shown as light thick line with diamond markers.
}
\providecommand{\bbobppfigslegend}[1]{
Expected running time (\ERT\ in number of $f$-evaluations
                    as $\log_{10}$ value), divided by dimension for target function value $10^{-8}$
                    versus dimension. Slanted grid lines indicate quadratic scaling with the dimension. Different symbols correspond to different algorithms given in the legend of #1. Light symbols give the maximum number of function evaluations from the longest trial divided by dimension. Black stars indicate a statistically better result compared to all other algorithms with $p<0.01$ and Bonferroni correction number of dimensions (six).  
Legend: 
{\color{NavyBlue}$\circ$}: \algorithmA
, {\color{Magenta}$\diamondsuit$}: \algorithmB
, {\color{Orange}$\star$}: \algorithmC
, {\color{CornflowerBlue}$\triangledown$}: \algorithmD
, {\color{red}$\varhexagon$}: \algorithmE
, {\color{YellowGreen}$\triangle$}: \algorithmF
, {\color{cyan}$\pentagon$}: \algorithmG
}
% define some COCO/dvipsnames colors because
% ACM style does not allow to use them directly
\definecolor{NavyBlue}{HTML}{000080}
\definecolor{Magenta}{HTML}{FF00FF}
\definecolor{Orange}{HTML}{FFA500}
\definecolor{CornflowerBlue}{HTML}{6495ED}
\definecolor{YellowGreen}{HTML}{9ACD32}
\definecolor{Gray}{HTML}{BEBEBE}
\definecolor{Yellow}{HTML}{FFFF00}
\definecolor{GreenYellow}{HTML}{ADFF2F}
\definecolor{ForestGreen}{HTML}{228B22}
\definecolor{Lavender}{HTML}{FFC0CB}
\definecolor{SkyBlue}{HTML}{87CEEB}
\definecolor{NavyBlue}{HTML}{000080}
\definecolor{Goldenrod}{HTML}{DDF700}
\definecolor{VioletRed}{HTML}{D02090}
\definecolor{CornflowerBlue}{HTML}{6495ED}
\definecolor{LimeGreen}{HTML}{32CD32}

\providecommand{\ntables}{7}
\providecommand{\ntables}{7}
\providecommand{\ntables}{7}
\providecommand{\pptablesfooter}{
\end{tabularx}
}
\providecommand{\pptablesheader}{
\begin{tabularx}{1.0\textwidth}{@{}c@{}|*{7}{@{}r@{}X@{}}|@{}r@{}@{}l@{}}
$\Delta f_\mathrm{opt}$ & \multicolumn{2}{@{\,}l@{\,}}{1e1} & \multicolumn{2}{@{\,}l@{\,}}{1e0} & \multicolumn{2}{@{\,}l@{\,}}{1e-1} & \multicolumn{2}{@{\,}l@{\,}}{1e-2} & \multicolumn{2}{@{\,}l@{\,}}{1e-3} & \multicolumn{2}{@{\,}l@{\,}}{1e-5} & \multicolumn{2}{@{\,}l@{\,}}{1e-7} & \multicolumn{2}{|@{}l@{}}{\#succ}\\\hline
}
\providecommand{\algGtables}{\StrLeft{PSO EDA}{\ntables}}
\providecommand{\algFtables}{\StrLeft{PSO Bounds}{\ntables}}
\providecommand{\algEtables}{\StrLeft{PSO}{\ntables}}
\providecommand{\algDtables}{\StrLeft{JADE}{\ntables}}
\providecommand{\algCtables}{\StrLeft{DEAE}{\ntables}}
\providecommand{\algBtables}{\StrLeft{DE}{\ntables}}
\providecommand{\algAtables}{\StrLeft{Bin GA}{\ntables}}
\providecommand{\ntables}{7}
\providecommand{\ntables}{7}
\providecommand{\ntables}{7}
\providecommand{\bbobpptablesmanylegend}[1]{%
        Expected runtime (\ERT\ in number of function 
        evaluations) divided by the respective best \ERT\ measured during BBOB-2009 in
        #1.
        This \ERT\ ratio and, in braces as dispersion measure, the half difference between
        10 and 90\%-tile of bootstrapped run lengths appear for each algorithm and 
        %
        target, the corresponding reference \ERT\
        in the first row. The different target \Df-values are shown in the top row.
        \#succ is the number of trials that reached the (final) target
        $\fopt + 10^{-8}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the target in the last column was never reached.
        Entries, succeeded by a star, are statistically significantly better (according to
        the rank-sum test) when compared to all other algorithms of the table, with
        $p = 0.05$ or $p = 10^{-k}$ when the number $k$ following the star is larger
        than 1, with Bonferroni correction by the number of functions (24). A $\downarrow$ indicates the same tested against the best algorithm from BBOB 2009. Best results are printed in bold.
        \cocoversion}
\providecommand{\algsfolder}{Bin_G_DE_DEAE_JADE_PSO_PSO_B_PSO_E_et_al/}
\providecommand{\algorithmA}{Bin GA}
\providecommand{\algorithmB}{DE}
\providecommand{\algorithmC}{DEAE}
\providecommand{\algorithmD}{JADE}
\providecommand{\algorithmE}{PSO}
\providecommand{\algorithmF}{PSO Bounds}
\providecommand{\algorithmG}{PSO EDA}
